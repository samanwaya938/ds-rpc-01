# ğŸ“‚ Multiple Role-Based Document Retrieval with LLMs

## ğŸš€ Overview

This project is a **Role-Based Retrieval-Augmented Generation (RAG) System** built with **FastAPI**, **Streamlit**, and **LangChain**, leveraging **OpenAI** and **Google GenAI APIs**. It enables users to log in with a specific role and retrieve relevant answers based only on the data allowed for that role.

### ğŸ”¹ Use Case

* âœ‰ï¸ An HR personnel can retrieve HR-specific data.
* ğŸ¢ A marketing manager can only access marketing-related information.
* ğŸ“ Custom roles with isolated document knowledgebases.

Each role has a dedicated **vectorstore** created with **FAISS** using pre-uploaded documents. At query time, only the appropriate store is used to generate a context-aware response.

---

## ğŸ“Š Tech Stack

| Category      | Tools Used                      |
| ------------- | ------------------------------- |
| Backend       | FastAPI, Uvicorn                |
| Frontend      | Streamlit                       |
| LLM Interface | LangChain, OpenAI API           |
| Embeddings    | Google Generative AI Embeddings |
| Vector DB     | FAISS                           |
| Environment   | Python 3.10.8, Docker           |
| Secrets Mgmt  | dotenv (.env)                   |

---

## ğŸ“ Folder Structure

```
my_project/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI backend entrypoint
â”‚   â”‚   â”œâ”€â”€ auth.py          # Authentication logic
â”‚   â”‚   â”œâ”€â”€ chat.py          # Chat + Retrieval logic
â”‚   â”‚   â””â”€â”€ store.py         # Vectorstore retrieval logic
â”‚   â””â”€â”€ frontend/
â”‚       â””â”€â”€ app.py           # Streamlit frontend app
â”œâ”€â”€ db_stores/               # Contains vectorstore_hr, vectorstore_finance, etc.
â”œâ”€â”€ resources/               # All the role specific custom data 
â”‚
â”œâ”€â”€ requirements.txt         # Project dependencies
â”œâ”€â”€ Dockerfile               # Docker configuration
â”œâ”€â”€ .env                     # API keys (not included in repo)
â”œâ”€â”€ .dockerignore            # Docker ignore rules
â”œâ”€â”€ setup.py                 # Project Setup File
â”œâ”€â”€ README.md                # Instruction file
```

---

## ğŸ”§ Local Setup Instructions

### âœ… Create virtual environment

```bash
python -m venv venv
```

### âœ… Activate the virtual environment

* **Windows:**

```bash
venv\Scripts\activate
```

* **Unix/macOS:**

```bash
source venv/bin/activate
```

### âœ… Install dependencies

```bash
pip install -r requirements.txt
```

### Create .env file

Create .env file in the root directory and save your own OPENAI_API_KEY and GGOGLE_API_KEY. Make sure their should not be any whitespace around "="

### Run the store.py file

To create vectore database run the store.py file using the following command. It has to be run only once. Once run the db_stores folder will be created in the root directory and it will be conatains all the role specific vector store.
```bash
python app/backend/store.py
```

### ğŸŒ Run the application

* **Backend (FastAPI)**

```bash
uvicorn app.backend.main:app --reload
```

* **Frontend (Streamlit)**

```bash
streamlit run app/frontend/app.py
```

---

## ğŸš§ Docker Usage

### ğŸ“¦ Build Image

```bash
docker buildx build -t rag-multirole:latest .
```

### ğŸšš Pull from DockerHub

```bash
docker pull samanwaya/rag-multirole
```

### ğŸ”„ Run Docker Container with User API Keys

```bash
docker run -p 8000:8000 -p 8501:8501 \
  --env OPENAI_API_KEY="your_openai_key" \
  --env GOOGLE_API_KEY="your_google_key" \
  your-dockerhub-username/rag-multirole:latest
```

> âš ï¸ `.env` file should NOT be part of the Docker image. Users must pass their own keys during runtime using `--env`.

---

## âš–ï¸ Environment Variables

| Variable Name    | Required | Description                           |
| ---------------- | -------- | ------------------------------------- |
| `OPENAI_API_KEY` | Yes      | OpenAI GPT models                     |
| `GOOGLE_API_KEY` | Yes      | Google GenAI embeddings (vectorstore) |

---

## ğŸ“… Usage Instructions

1. **Login First**
   
These are sample data to login and test

   * ID: `alice`
   * Password: `1234`
   * Role: `engineering`
---  
   * ID: `bob`
   * Password: `abcd`
   * Role: `hr`
---  
   * ID: `charlie`
   * Password: `xyz`
   * Role: `finance`
---  
   * ID: `harry`
   * Password: `1122`
   * Role: `general`
--- 
   * ID: `jack`
   * Password: `xxyyzz`
   * Role: `marketing`
---
2. ***Ask Questions***

    After successful login, you can ask role-specific questions using the chat input. The application uses the relevant vectorstore for the selected role.

   Example:

       "What are the onboarding steps for new employees?"

3. ***Behind the Scenes***

   * Role general loads vectorstore_general
   * Role finance loads vectorstore_finance
   * Stored vector DBs are in db_stores/

---

## ğŸ“ˆ Example Roles & Vectorstores

| Role    | Folder Path                     |
| ------- | ------------------------------- |
| HR      | `db_stores/vectorstore_hr`      |
| Finance | `db_stores/vectorstore_finance` |
| General | `db_stores/vectorstore_general`   |

---

## ğŸ“„ Screenshots
### Login Page
![image](https://github.com/user-attachments/assets/fd6647e7-c238-4ebb-a8fc-bfb356770262)

### Chat Page
![image](https://github.com/user-attachments/assets/40179358-2029-4991-bd01-ce0c2e0cb436)


## ğŸ“¹ Demo Video

*(To be added)*

---

## ğŸ“› Badges

* Python: 3.10.8
* Docker: Image available on DockerHub

---

## ğŸ‘‰ Contributing

Want to contribute or suggest improvements? Feel free to raise issues or submit pull requests.

---

## ğŸ™ Acknowledgements

* [LangChain](https://github.com/langchain-ai/langchain)
* [OpenAI](https://openai.com)
* [Google Generative AI](https://aistudio.google.com/)
* [Streamlit](https://streamlit.io)
* [FastAPI](https://fastapi.tiangolo.com)

---

## âœ¨ License

MIT â€” feel free to use and modify with attribution.
